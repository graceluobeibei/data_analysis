{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d178b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_columns() -> list[str]:\n",
    "    import pandas as pd\n",
    "    # read the columsn from excel\n",
    "    # Feature,user_id,gender,visit_city,avg_price,is_supervip,ctr_30,ord_30,total_amt_30,shop_id,item_id,city_id,district_id,shop_aoi_id,shop_geohash_6,shop_geohash_12,brand_id,category_1_id,merge_standard_food_id,rank_7,rank_30,rank_90,shop_id_list,item_id_list,category_1_id_list,merge_standard_food_id_list,brand_id_list,price_list,shop_aoi_id_list,shop_geohash6_list,timediff_list,hours_list,time_type_list,weekdays_list,times,hours,time_type,weekdays,geohash12\n",
    "    df = pd.read_excel('../../data/D1_0_top_10.xlsx')\n",
    "    # read the sheet names\n",
    "    sheet_names = pd.ExcelFile('../../data/D1_0_top_10.xlsx').sheet_names\n",
    "    print(\"Reading Sheet list from ../../data/D1_0_top_10.xlsx:\", sheet_names)\n",
    "    # read data for the sheet named \"columns\"\n",
    "    df_columns = pd.read_excel('../../data/D1_0_top_10.xlsx', sheet_name='D1_0_top10')\n",
    "    columns = df_columns.loc[1] # access the second row\n",
    "    return columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22cfe5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_rows.shape =  (266, 39)\n",
      "==============================================\n",
      "2\n",
      "-99      430\n",
      "1       3681\n",
      "2       5623\n",
      "<NA>     266\n",
      "Name: 0, dtype: int64\n",
      "sum =  10000\n",
      "===== 按性别统计成功人次(column 0) ===\n",
      "2\n",
      "-99     14\n",
      "1       64\n",
      "2       80\n",
      "<NA>     4\n",
      "Name: 0, dtype: int64\n",
      "===== 按性别统计成功概率 sum(column 0) / count(column 0) ===\n",
      "2\n",
      "-99     0.032558\n",
      "1       0.017387\n",
      "2       0.014227\n",
      "<NA>    0.015038\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read top 10000 rows, column 0 and column 2 are integers\n",
    "df = pd.read_csv('../../data/raw/D1_0_top_10k.csv', header=None, nrows=10000, dtype={0: int, 2: \"Int64\"})\n",
    "# print(df.head(1))\n",
    "\n",
    "# # select the rows where column 2 is null\n",
    "null_rows = df[df[2].isnull()]\n",
    "# check the number of null rows in column 2\n",
    "print(\"null_rows.shape = \", null_rows.shape) # return the shape (rows, columns)\n",
    "# print(\"null_rows.count().sum() = \", null_rows.count()) # check the number of non-null rows in column 2\n",
    "\n",
    "# count the column 0, group by column 2, including null values\n",
    "print(\"==============================================\")\n",
    "count = df.groupby(2, dropna=False)[0].count()\n",
    "print(count)  # display the count\n",
    "print(\"sum = \", count.sum())  # sum should be 10000 \n",
    "\n",
    "# sum the column 0, group by column 2, including null values\n",
    "print(\"===== 按性别统计成功人次(column 0) ===\")\n",
    "sum = df.groupby(2, dropna=False)[0].sum()\n",
    "print(sum)  # display the sum\n",
    "\n",
    "print(\"===== 按性别统计成功概率 sum(column 0) / count(column 0) ===\")\n",
    "prob = sum / count\n",
    "print(prob)  # display the probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除 Metal 相关部分，在MACOS M1上使用并行化计算\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "df = pd.DataFrame({\"a\": range(1_000_000), \"b\": range(1_000_000)})\n",
    "\n",
    "# 使用并行化替代 Metal GPU 加速\n",
    "@njit(parallel=True)\n",
    "def compute_sum(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "# 执行并行计算\n",
    "df[\"sum\"] = compute_sum(df[\"a\"].values, df[\"b\"].values)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试MAC M1 GPU加速\n",
    "import pandas as pd\n",
    "from numba import njit, objmode\n",
    "from numba import metal  # Metal后端\n",
    "\n",
    "df = pd.DataFrame({\"a\": range(1_000_000), \"b\": range(1_000_000)})\n",
    "\n",
    "# 用Numba加速自定义函数（M1 GPU执行）\n",
    "@njit(target_backend=\"metal\")\n",
    "def compute_sum(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "# 执行GPU运算\n",
    "df[\"sum\"] = compute_sum(df[\"a\"].values, df[\"b\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f825c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 兼容方式：避免使用 PyArrow 字符串后端\n",
    "pd.set_option(\"mode.string_storage\", \"python\")\n",
    "print(\"pandas string_storage:\", pd.get_option(\"mode.string_storage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 Pandas 读取 大数据文件，分块处理，适合简单的数据处理，复杂的分析建议用 Dask\n",
    "import pandas as pd\n",
    "import glob\n",
    "results = []\n",
    "for file in glob.glob('../../data/raw/*.csv'):\n",
    "    chunk = pd.read_csv(file, dtype={'col': 'float32'}, usecols=['key_cols'])\n",
    "    results.append(chunk['col'].mean())  # 累积统计\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data: ../../data/raw/D1_0.csv\n",
      "../../data/raw/D1_0.csv already exists, no need to unzip.\n",
      "Reading CSV file from: ../../data/raw/D1_0.csv\n",
      "Reading Sheet list from ../../data/D1_0_top_10.xlsx: ['D1_0_top10', 'columns']\n",
      "===============================================================\n",
      "Number of partitions: 128, Total rows: 2170299\n",
      "===============================================================\n",
      "CPU times: user 3min 35s, sys: 38.5 s, total: 4min 14s\n",
      "Wall time: 4min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender\n",
       "2       1122603\n",
       "1        760600\n",
       "-99      184221\n",
       "<NA>     102875\n",
       "Name: count, dtype: int64[pyarrow]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import subprocess\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "CSV_PATH = (\"../../data/raw/D1_0.csv\") # 可以替换为*.csv\n",
    "print(\"Preparing data:\", CSV_PATH)\n",
    "file_exists = os.path.exists(CSV_PATH)\n",
    "if file_exists:\n",
    "    print(f\"{CSV_PATH} already exists, no need to unzip.\")\n",
    "else:\n",
    "    subprocess.run([\"gunzip\", \"--keep\", CSV_PATH+\".gz\"], check=True)\n",
    "\n",
    "print(\"Reading CSV file from:\", CSV_PATH)\n",
    "# 强制所有列为 object 类型，避免自动推断触发 PyArrow StringArray\n",
    "df = dd.read_csv(\n",
    "            str(CSV_PATH),\n",
    "            header = None,\n",
    "            names = read_data_columns(),\n",
    "            sep=\",\",\n",
    "            encoding=\"utf-8\",  # 如果报编码错，试试 \"latin1\"\n",
    "            dtype=str,  # 先全部读为字符串，保证能读进来\n",
    "            assume_missing=True,\n",
    "            blocksize=\"128MB\", # for gzip files using: blocksize=None,\n",
    "            sample=256_000,  # 更小样本，减少不稳定推断\n",
    "            on_bad_lines=\"warn\",  # 或 \"skip\" 跳过坏行\n",
    "            engine=\"python\",  # Python引擎更宽容，但速度较慢\n",
    "            # quotechar='\"',         # 如果有引号且格式复杂，保留或按需调整\n",
    "            # na_filter=False,       # 如不希望将特定字符串视为 NA，可关闭\n",
    "        )\n",
    "# print(df.tail(1))  # 输出最后一行  # 仅触发首块，验证能构成 DataFrame建\n",
    "print(\"===============================================================\")\n",
    "# print(f\"Second column of the first row: {df.iloc[0, 1]}\")\n",
    "# 统计总行数\n",
    "nparts = df.npartitions\n",
    "total_rows = df.shape[0].compute()\n",
    "print(f\"Number of partitions: {nparts}, Total rows: {total_rows}\")\n",
    "print(\"===============================================================\")\n",
    "\n",
    "df['gender'].compute().value_counts(dropna=False)  # 计算性别列的值计数，包括缺失值, elapse: CPU times: user 3min 35s, sys: 38.5 s, total: 4min 14s\n",
    "# df['gender'].value_counts(dropna=False).compute()  # 计算性别列的值计数，包括缺失值, elapse: CPU times: user 3min 34s, sys: 28.9 s, total: 4min 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec5026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "This is a test cell.\n",
      "CPU times: user 53 μs, sys: 4 μs, total: 57 μs\n",
      "Wall time: 56 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Hello World\")\n",
    "print(\"This is a test cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
